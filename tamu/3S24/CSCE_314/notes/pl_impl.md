# Programming Language Implementation
## A Tour of Language Implementation
- Here we discuss characterization of programming languages, and the implementation of programming languages.
- The compiler checks all the syntax and semantics of the program, and then translates the program into machine code.
- Understanding these steps will help you understand how a compiler works and the errors it can produce.
- Ultimately this will help learning new programming languages.
### Programming Language Characteristics
- There exist different approaches to:
    - Decribe computation/instruct computing devices
        - Imperative
            - C/C++
            - Java
            - Python
        - Declarative
            - SQL
            - Prolog
            - Haskell
        - Functional
            - Lisp
            - Scheme
            - Haskell
            - Sort of python
    - Communicate idea between humans
        - Procedural
            - FORTRAN
            - C
            - Pascal
        - Object-Oriented
            - Java
            - Eiffel
        - Domain-Specific
            - SQL
            - LaTeX
- Programming langauges are **specified** by:
    - Semantics
        - Meaning of the program
    - Syntax
        - Structure of the program
- All sentences should be **unambiguously** specified, with semantics and syntax.
### Programming Language Expressiveness
- The level of abstraction can also characterize programming languages.
- **High-level** languages are more abstract, and are closer to human language.
- **Low-level** languages are closer to machine language.
- Programming langauges tend to become more abstract over time.
### Defining Programming Languages
- Syntax: Define the set of valid programs
    - Usually defined with the help of grammars and other conditions
- Semantics: Define the meaning of the programs
### Implementing a Programming Language
- The task is to undo abstraction, match assembly to the source code.
- This process is usually called compilation, even though the scope of tasks during compilation varies.
- The process of undoing abstraction happens in this kind of process:
    - Source code
    - Lexical Analysis / Lexer
        - Separates the symbols and checks if the code is well formed
        - Produces a sequence of lexical components, or **tokens**
        - Places the tokens in a token table
        - If there is an error in symbols or keywords or syntax, the lexer will produce an error message, and compilation will stop.
        - Final output is a stream of tokens or token table
    - Syntax Analysis / Parser
        - Checks the syntactic structure of the program using the stream of tokens from the lexer
        - For example, the Glasgow Haskell Compiler would check if an `if` statement has a corresponding `then` statement
        - If all syntax is correct, the parser will produce a syntax tree, sometimes called a **parse tree**
        - If there is an error in syntax, the parser will produce an error message, and compilation will stop.
        - Final output is a syntax tree/parse tree
    - Type checker
        - Annotates the syntax tree with type information
        - Checks if all types are used correctly
        - Outputs a type-annotated syntax tree
    - At this point, the program can be run in an interpreter, or compiled to machine code.
    - Many compilers these days are optimizing, so the annotated syntax tree will be optimized before being compiled to machine code.
    - In the case of Java, the Java compiler will produce bytecode, which is then run in the Java Virtual Machine (JVM).
- Recap:
    - Lexical Analysis
        - From a stream of characters to a stream of tokens
        - `if (a == b) return;` would translate to:
        - `keyword['if']`
        - `symbol['(']`
        - `identifier['a']`
        - `symbol['==']`
        - `identifier['b']`
        - `symbol[')']`
        - `keyword['return']`
        - `symbol[';']`
    - Syntax Analysis
        - From a stream of tokens to a syntax tree
        - `if` statement
            - expression
                - `==` operator
                    - identifier
                        - `a`
                    - identifier
                        - `b`
            - statement
                - `return` statement
    - Type Checker
        - From a syntax tree to a type-annotated syntax tree
        - `if` statement: OK
            - expression: bool
                - `==` operator: integer equality
                    - identifier: integer
                        - `a`
                    - identifier: integer
                        - `b`
            - statement: OK
                - `return` statement: void
    - Optimization
        - Say we have that `a` and `b` always have the same value, we can optimize the `==` operator to always return `true`.
        - Then the tree just becomes:
            - `return` statement: void
    - Code Generation
        - Undos the abstraction, and matches the syntax tree to machine code.
            - Control structures become jumps and conditional jumps
                - These are basically `goto` statements
            - Variables become memory addresses
            - Variable names become addresses
            - ADTs disappear, and are broken down to the most primitive types
            - Expressions become load memory, register operations, and store memory
### Typical Errors at Each Stage
- Lexical analysis catches errors in symbols and keywords
    - misspelled keywords
    - wrong symbols
- Syntax analysis ensures that proper experssions are formed
    - e.g. cant have `if` without `then` in Haskell
    - e.g. cant use `+` on `if` statements
- Type checking ensures that types are used correctly
    - Catches type errors
## Formal Languages: Motivation
- We describe the syntax of programming languages using a **phrase structure grammar**.
- A phrase structure grammar is a universal set of rules that can generate all the sentences in a language.
- Regular expressions are a simple form of phrase structure grammar.
- Formal languages are the foundational of computational complexity theory.
### Formal languages
- An **alphabet** $A$ is a set of letters, symbols, or tokens.
- The **binary alphabet** is $\{0, 1\}$, and is used very often in computer science.
- We denote $A^*$ as the set of all strings of any finite length over the alphabet $A$.
    - $A^* = A^0 \cup A^1 \cup A^2 \cup \dots$
    - The exponent denotes the length of the string.
    - $A^0 = \{\epsilon\}$
- An element $s$ of $A^*$ is a **string**, and is given by a concatenation of symbols from $A$.
- The **empty string** is denoted by $\epsilon$.
- A **formal language** over an alphabet $A$ is a subset of $A^*$.
- We refer to the elements of $A^*$ as **words**, or sometimes **sentences**, over the alphabet $A$.
## Formal Languages: Grammars
- The American linguist Noam Chomsky introduced the concept of a **phrase structure grammar**.
- He grouped formal languages into four nested subsets of more and more specific types of grammars.
- 
## Formal Languages: Chomsky Hierarchy
