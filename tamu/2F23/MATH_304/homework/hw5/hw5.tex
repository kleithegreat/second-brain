\documentclass{article}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{fancyhdr}
\usepackage{enumerate}

\pagestyle{fancy}
\fancyhf{}
\lhead{5th Homework - MATH 304 508}
\rhead{Kevin Lei}
\renewcommand{\headrulewidth}{0.4pt}

\begin{document}

\section*{Question 1}
Consider the following collections of polynomials in $\mathbb{P}_2$:
\begin{enumerate}[(a)]
    \item $p_1(x) = 1, \quad p_2(x) = x + 1, \quad p_3(x) = x^2$.
    \item $p_1(x) = x - 1, \quad p_2(x) = x + 1, \quad p_3(x) = x^2 - 1$.
    \item $p_1(x) = x^2 - 1, \quad p_2(x) = x^2 + 1, \quad p_3(x) = x^2$.
\end{enumerate}
Decide in each case if these vectors are linearly independent.
Write the dimension of the subspace $S := span\{p_1, p_2, p_3\}$ in each case.
In which case(s) would we have that $S = \mathbb{P}_2$? Explain your answer.

\medskip
\noindent
\textbf{Answer:} To check for linear independence, we can use the Wronskian determinant.
\begin{enumerate}[(a)]
    \item
        \begin{flalign*}
            W(p_1, p_2, p_3) = \begin{vmatrix} 1 & x + 1 & x^2 \\ 0 & 1 & 2x \\ 0 & 0 & 2 \end{vmatrix}
            = 2 \begin{vmatrix} 1 & x + 1 \\ 0 & 1 \end{vmatrix}
            = 2 &&
        \end{flalign*}
        \newline
        Since $W(p_1, p_2, p_3) \neq 0$, the vectors are linearly independent.
        The dimension of the subspace $S := span\{p_1, p_2, p_3\}$ is 3, since there are 3 linearly independent vectors in its basis.
        \newline
        In this case, we have that $S = \mathbb{P}_2$.
        \begin{proof}
            To show that $S = \mathbb{P}_2$, we need to show that $span\{p_1, p_2, p_3\} = \mathbb{P}_2$.
            Let $p(x) = ax^2 + bx + c$ be an arbitrary polynomial in $\mathbb{P}_2$.
            Our goal is to show that $p(x)$ can be shown as a linear combination of $p_1, p_2, p_3$.
            That means we must find $\alpha, \beta, \gamma$ such that:
            $$ \alpha p_1(x) + \beta p_2(x) + \gamma p_3(x) = ax^2 + bx + c $$
            Substituting in $p_1, p_2, p_3$, we have:
            $$ \alpha + \beta(x + 1) + \gamma x^2 = ax^2 + bx + c $$
            $$ \alpha + \beta x + \beta + \gamma x^2 = ax^2 + bx + c $$
            $$ \gamma x^2 + \beta x + (\alpha + \beta) = ax^2 + bx + c $$
            Equating coefficients, we have:
            $$ \gamma = a, \quad \beta = b, \quad \alpha + \beta = c $$
            Since $\beta = b$, we have that $\alpha = c - b$.
            Substituting everyting back into the original equation, we have:
            $$ (c - b) + b(x + 1) + ax^2 = ax^2 + bx + c $$
            Now we can see that $p(x)$ can be written as a linear combination of $p_1, p_2, p_3$.
            Therefore, $span\{p_1, p_2, p_3\} = \mathbb{P}_2$, and $S = \mathbb{P}_2$.
        \end{proof}
    \item
        \begin{flalign*}
            W(p_1, p_2, p_3) &= \begin{vmatrix} x - 1 & x + 1 & x^2 - 1 \\ 1 & 1 & 2x \\ 0 & 0 & 2x \end{vmatrix}
            = 2x \begin{vmatrix} x - 1 & x + 1 \\ 1 & 1 \end{vmatrix} && \\
            &= 2x (x - 1 - x - 1) = -4x &&
        \end{flalign*}
        \newline
        Since $W(p_1, p_2, p_3) \neq 0$, the vectors are linearly independent.
        The dimension of the subspace $S := span\{p_1, p_2, p_3\}$ is 3, since there are 3 linearly independent vectors in its basis.
        \newline
        In this case, we have that $S = \mathbb{P}_2$.
        \begin{proof}
            To show that $S = \mathbb{P}_2$, we need to show that $span\{p_1, p_2, p_3\} = \mathbb{P}_2$.
            Let $p(x) = ax^2 + bx + c$ be an arbitrary polynomial in $\mathbb{P}_2$.
            Our goal is to show that $p(x)$ can be shown as a linear combination of $p_1, p_2, p_3$.
            That means we must find $\alpha, \beta, \gamma$ such that:
            $$ \alpha p_1(x) + \beta p_2(x) + \gamma p_3(x) = ax^2 + bx + c $$
            Substituting in $p_1, p_2, p_3$, we have:
            $$ \alpha(x - 1) + \beta(x + 1) + \gamma(x^2 - 1) = ax^2 + bx + c $$
            $$ \alpha x - \alpha + \beta x + \beta + \gamma x^2 - \gamma = ax^2 + bx + c $$
            $$ \gamma x^2 + (\alpha + \beta) x + (\beta - \alpha - \gamma) = ax^2 + bx + c $$
            Equating coefficients, we have:
            $$ \gamma = a, \quad \alpha + \beta = b, \quad \beta - \alpha - \gamma = c $$
            Now we have arbitrary elements $a, b, c$ in terms of $\alpha, \beta, \gamma$.
            To solve for $\alpha, \beta, \gamma$ in terms of $a, b, c$, we can use the augmented matrix:
            $$ \left[\begin{array}{ccc|ccc}
                0 & 0 & \gamma & a & 0 & 0 \\
                \alpha & \beta & 0 & 0 & b & 0 \\
                -\alpha & \beta & -\gamma & 0 & 0 & c
            \end{array}\right] $$
            Using row operations, we have the following equivalent matricies:
            $$
            \left[\begin{array}{ccc|ccc}
                0 & 0 & \gamma & a & 0 & 0 \\
                0 & 2\beta & -\gamma & 0 & b & c \\
                -\alpha & \beta & 0 & a & 0 & c \\
            \end{array}\right] \sim
            \left[\begin{array}{ccc|ccc}
                0 & 0 & \gamma & a & 0 & 0 \\
                0 & 2\beta & 0 & a & b & c \\
                \alpha & -\beta & 0 & -a & 0 & -c \\
            \end{array}\right] \sim
            \left[\begin{array}{ccc|ccc}
                0 & 0 & \gamma & a & 0 & 0 \\
                0 & \beta & 0 & \frac{a}{2} & \frac{b}{2} & \frac{c}{2} \\
                \alpha & 0 & 0 & -\frac{a}{2} & \frac{b}{2} & -\frac{c}{2} \\
            \end{array}\right]
            $$
            From the last matrix, we can see that $\alpha = -\frac{a}{2} + \frac{b}{2} - \frac{c}{2}$, 
            $\beta = \frac{a}{2} + \frac{b}{2} + \frac{c}{2}$, and $\gamma = a$.
            Since we can write $ax^2 + bx + c$ as a linear combination of $p_1, p_2, p_3$, 
            we have proven that $span\{p_1, p_2, p_3\} = \mathbb{P}_2$, and $S = \mathbb{P}_2$.
        \end{proof}
    \item
        \begin{flalign*}
            W(p_1, p_2, p_3) &= \begin{vmatrix} x^2 - 1 & x^2 + 1 & x^2 \\ 2x & 2x & 2x \\ 2 & 2 & 0 \end{vmatrix}
            = 2 \begin{vmatrix} x^2 - 1 & x^2 + 1 \\ 2x & 2x \end{vmatrix} && \\
            &= 2 (2x^3 - 2x - 2x^3 - 2x) = -8x &&
        \end{flalign*}
        \newline
        Since $W(p_1, p_2, p_3) \neq 0$, the vectors are linearly independent.
        The dimension of the subspace $S := span\{p_1, p_2, p_3\}$ is 3, since there are 3 linearly independent vectors in its basis.
        \newline
        In this case, $S \neq \mathbb{P}_2$, since none of the polynomials in $S$ have a term of degree 1.
        Therefore, there is no way to represent a polynomial of degree 1 as a linear combination of $p_1, p_2, p_3$.
\end{enumerate}

\newpage

\section*{Question 2}
Consider the following collections of smooth functions $[0,1]$:
\begin{enumerate}
    \item $f_1(x) = x^2$, $f_2(x) = x^{\frac{1}{2}}$
    \item $f_1(x) = \cos(x)$, $f_2(x) = \sin(x)$
    \item $f_1(x) = 1$, $f_2(x) = \frac{e^x + e^{-x}}{2}$, $f_3(x) = \frac{e^x - e^{-x}}{2}$
\end{enumerate}
Decide in each case if these vectors (functions) are linearly independent.

\medskip
\noindent
\textbf{Answer:} To check for linear independence, we can use the Wronskian determinant.
\begin{enumerate}
    \item
        \begin{flalign*}
            W(f_1, f_2) &= \begin{vmatrix} x^2 & x^{\frac{1}{2}} \\ 2x & \frac{1}{2}x^{-\frac{1}{2}} \end{vmatrix}
            = (x^2 \cdot \frac{1}{2}x^{-\frac{1}{2}}) - (x^{\frac{1}{2}} \cdot 2x) = \frac{1}{2}x^{\frac{3}{2}} - 2x^{\frac{3}{2}} = -\frac{3}{2}x^{\frac{3}{2}} &&
        \end{flalign*}
        \newline
        Since $W(f_1, f_2) \neq 0$, the vectors are linearly independent.
    \item
        \begin{flalign*}
            W(f_1, f_2) &= \begin{vmatrix} \cos(x) & \sin(x) \\ -\sin(x) & \cos(x) \end{vmatrix}
            = \cos^2(x) + \sin^2(x) = 1 &&
        \end{flalign*}
        \newline
        Since $W(f_1, f_2) \neq 0$, the vectors are linearly independent.
    \item
        \begin{flalign*}
            W(f_1, f_2, f_3) 
            &= \begin{vmatrix} 1 & \frac{e^x + e^{-x}}{2} & \frac{e^x - e^{-x}}{2} \\ 
                0 & \frac{e^x - e^{-x}}{2} & \frac{e^x + e^{-x}}{2} \\ 
                0 & \frac{e^x + e^{-x}}{2} & \frac{e^x - e^{-x}}{2} \end{vmatrix}
            = \begin{vmatrix} \frac{e^x - e^{-x}}{2} & \frac{e^x + e^{-x}}{2} \\ 
                \frac{e^x + e^{-x}}{2} & \frac{e^x - e^{-x}}{2} \end{vmatrix} && \\
            &= \frac{e^x - e^{-x}}{2} \cdot \frac{e^x - e^{-x}}{2} - \frac{e^x + e^{-x}}{2} \cdot \frac{e^x + e^{-x}}{2} && \\
            &= \frac{e^{2x} - 2 + e^{-2x}}{4} - \frac{e^{2x} + 2 + e^{-2x}}{4} && \\
            &= 0 &&
        \end{flalign*}
        \newline
        Since $W(f_1, f_2, f_3) = 0$, the vectors are linearly dependent.
\end{enumerate}

\newpage

\section*{Question 3}
Find the dimension of the space spanned by the functions
$$1, \medspace \cos(2x), \medspace \cos^2(x)$$
\noindent
\textbf{Answer:}
To find the dimension of the space spanned by these vectors, first we need to check for linear independence.
Since these vectors are functions, we can use the Wronskian determinant.
\begin{flalign*}
    W(1, \cos(2x), \cos^2(x)) 
    &= \begin{vmatrix} 1 & \cos(2x) & \cos^2(x) \\ 0 & -2\sin(2x) & -2\sin(x)\cos(x) \\ 0 & -4\cos(2x) & 2\sin^2(x)-2cos^2(x) \end{vmatrix} && \\
    &= (-2\sin(2x) \cdot (2\sin^2(x)-2\cos^2(x))) - (-4\cos(2x) \cdot (-2\sin(x)\cos(x))) && \\
    &= -4\sin(2x)\sin^2(x) + 4\sin(2x)\cos^2(x) - 8\sin(x)\cos(x)\cos(2x) && \\
    &= -4\sin(2x)(\sin^2(x) - \cos^2(x)) - 8\sin(x)\cos(x)\cos(2x) && \\
    &= -4\sin(2x)(-\cos(2x)) - 8\sin(x)\cos(x)\cos(2x) && \\
    &= 4\sin(2x)\cos(2x) - 4\sin(2x)\cos(2x) && \\
    &= 0 &&
\end{flalign*}
At this point, it is obvious that the vectors are linearly dependent, since the Wronskian determinant is 0, 
and there exists the double angle identity $\cos(2x) = \frac{1}{2}(1-\cos^2(x))$, 
which directly implies that one of the vectors can be written as a linear combination of the other two.
This means that if you choose any two vectors in this set, one of them will be redundant.
Therefore, the dimension of the space spanned by these vectors is 2.

\newpage

\section*{Question 4}
For each of the following find the transition matrix corresponding to the change of basis from $\{u_1, u_2\}$ to the standard one $\{e_1, e_2\}$:
\begin{enumerate}[(a)]
    \item $u_1 = (1,1)^T$, $u_2 = (-1,1)^T$
    \item $u_1 = (1,2)^T$, $u_2 = (2,5)^T$
    \item $u_1 = (0,1)^T$, $u_2 = (1,0)^T$
\end{enumerate}
Let
$$ v_1 = (3,2)^T, \quad v_2 = (4,3)^T $$
For each of the basis above find the transition matrix from $[v_1, v_2]$ to $[u_1, u_2]$.
\newline
Let
$$ x = (2,4)^T, \quad y = (1,1)^T, \quad z = (0,10) $$
Find the coordinates of $x, y, z$ with respect to each of the basis mentioned above.

\medskip
\noindent
\textbf{Answer}
\begin{enumerate}[(a)]
    \item 
    $u_1 = (1,1)^T$, $u_2 = (-1,1)^T$
    \newline
    The transition matrix from $\{u_1, u_2\}$ to $\{e_1, e_2\}$ is:
    $$ U = \begin{bmatrix} 1 & -1 \\ 1 & 1 \end{bmatrix} $$
    The transition matrix from $[v_1, v_2]$ to $[u_1, u_2]$ is $U^{-1}V$, 
    where $U$ is the transition matrix from $\{u_1, u_2\}$ to $\{e_1, e_2\}$, 
    and $V$ is the transition matrix from $\{v_1, v_2\}$ to $\{e_1, e_2\}$.
    We have that:
    $$ U^{-1} = \begin{bmatrix} \frac{1}{2} & \frac{1}{2} \\ -\frac{1}{2} & \frac{1}{2} \end{bmatrix} \quad 
    V = \begin{bmatrix} 3 & 4 \\ 2 & 3 \end{bmatrix} $$
    The transition matrix from $[v_1, v_2]$ to $[u_1, u_2]$ is:
    $$ U^{-1}V = \begin{bmatrix} \frac{1}{2} & \frac{1}{2} \\ -\frac{1}{2} & \frac{1}{2} \end{bmatrix} \begin{bmatrix} 3 & 4 \\ 2 & 3 \end{bmatrix}
     = \begin{bmatrix} \frac{3}{2} + \frac{2}{2} & \frac{4}{2} + \frac{3}{2} \\ -\frac{3}{2} - \frac{2}{2} & -\frac{4}{2} + \frac{3}{2} \end{bmatrix}
     = \begin{bmatrix} \frac{5}{2} & \frac{7}{2} \\ -\frac{5}{2} & -\frac{1}{2} \end{bmatrix} $$
    The coordinates of $x, y, z$ with respect to $\{u_1, u_2\}$ are:
    $$ 
    x = \begin{bmatrix} \frac{1}{2} & \frac{1}{2} \\ -\frac{1}{2} & \frac{1}{2} \end{bmatrix} \begin{bmatrix} 2 \\ 4 \end{bmatrix}
     = \begin{bmatrix} 3 \\ 1 \end{bmatrix}
    \quad
    y = \begin{bmatrix} \frac{1}{2} & \frac{1}{2} \\ -\frac{1}{2} & \frac{1}{2} \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix}
     = \begin{bmatrix} 1 \\ 0 \end{bmatrix}
    \quad
    z = \begin{bmatrix} \frac{1}{2} & \frac{1}{2} \\ -\frac{1}{2} & \frac{1}{2} \end{bmatrix} \begin{bmatrix} 0 \\ 10 \end{bmatrix}
     = \begin{bmatrix} 5 \\ 5 \end{bmatrix}
    $$
    \newline
    The coordinates of $x, y, z$ with respect to $\{v_1, v_2\}$ are:
    $$
    V^{-1} = \begin{bmatrix} 3 & 4 \\ 2 & 3 \end{bmatrix}^{-1} = \begin{bmatrix} 3 & -4 \\ -2 & 3 \end{bmatrix}
    $$
    $$
    x = \begin{bmatrix} 3 & -4 \\ -2 & 3 \end{bmatrix} \begin{bmatrix} 2 \\ 4 \end{bmatrix}
     = \begin{bmatrix} -10 \\ 8 \end{bmatrix}
    \quad
    y = \begin{bmatrix} 3 & -4 \\ -2 & 3 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix}
     = \begin{bmatrix} -1 \\ 1 \end{bmatrix}
    \quad
    z = \begin{bmatrix} 3 & -4 \\ -2 & 3 \end{bmatrix} \begin{bmatrix} 0 \\ 10 \end{bmatrix}
     = \begin{bmatrix} -40 \\ 30 \end{bmatrix}
    $$

    \item
    $u_1 = (1,2)^T$, $u_2 = (2,5)^T$
    The transition matrix from $\{u_1, u_2\}$ to $\{e_1, e_2\}$ is:
    $$ U = \begin{bmatrix} 1 & 2 \\ 2 & 5 \end{bmatrix} $$
    The transition matrix from $[v_1, v_2]$ to $[u_1, u_2]$ is $U^{-1}V$.
    We have the following:
    $$ U^{-1} = \begin{bmatrix} 5 & -2 \\ -2 & 1 \end{bmatrix} \quad
    V = \begin{bmatrix} 3 & 4 \\ 2 & 3 \end{bmatrix} $$
    $$ U^{-1}V = \begin{bmatrix} 15-4 & 20-6 \\ -6+2 & -8+3 \end{bmatrix} = 
    \begin{bmatrix} 11 & 14 \\ -4 & -5 \end{bmatrix} $$
    The coordinates of $x, y, z$ with respect to $\{u_1, u_2\}$ are:
    $$
    x = \begin{bmatrix} 5 & -2 \\ -2 & 1 \end{bmatrix} \begin{bmatrix} 2 \\ 4 \end{bmatrix}
     = \begin{bmatrix} 2 \\ 0 \end{bmatrix}
    \quad
    y = \begin{bmatrix} 5 & -2 \\ -2 & 1 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix}
     = \begin{bmatrix} 3 \\ -1 \end{bmatrix}
    \quad
    z = \begin{bmatrix} 5 & -2 \\ -2 & 1 \end{bmatrix} \begin{bmatrix} 0 \\ 10 \end{bmatrix}
     = \begin{bmatrix} -20 \\ 10 \end{bmatrix}
    $$
    \item
    $u_1 = (0,1)^T$, $u_2 = (1,0)^T$
    The transition matrix from $\{u_1, u_2\}$ to $\{e_1, e_2\}$:
    $$ U = \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix} $$
    The transition matrix from $[v_1, v_2]$ to $[u_1, u_2]$:
    $$ U^{-1} = \begin{bmatrix} 0 & -1 \\ -1 & 0 \end{bmatrix} \quad
    V = \begin{bmatrix} 3 & 4 \\ 2 & 3 \end{bmatrix} $$
    $$ U^{-1}V = \begin{bmatrix} 0-2 & 0-3 \\ -3-0 & -4-0 \end{bmatrix} =
    \begin{bmatrix} -2 & -3 \\ -3 & -4 \end{bmatrix} $$
    The coordinates of $x, y, z$ with respect to $\{u_1, u_2\}$ are:
    $$
    x = \begin{bmatrix} 0 & -1 \\ -1 & 0 \end{bmatrix} \begin{bmatrix} 2 \\ 4 \end{bmatrix}
     = \begin{bmatrix} -4 \\ -2 \end{bmatrix}
    \quad
    y = \begin{bmatrix} 0 & -1 \\ -1 & 0 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix}
     = \begin{bmatrix} -1 \\ -1 \end{bmatrix}
    \quad
    z = \begin{bmatrix} 0 & -1 \\ -1 & 0 \end{bmatrix} \begin{bmatrix} 0 \\ 10 \end{bmatrix}
     = \begin{bmatrix} -10 \\ 0 \end{bmatrix}
    $$
\end{enumerate}

\end{document}
